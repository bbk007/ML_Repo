{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2018/10/predicting-stock-price-machine-learningnd-deep-learning-techniques-python/\n",
    "https://www.researchgate.net/publication/259240183_A_Machine_Learning_Model_for_Stock_Market_Prediction\n",
    "https://towardsdatascience.com/machine-learning-techniques-applied-to-stock-price-prediction-6c1994da8001\n",
    "https://www.geeksforgeeks.org/twitter-sentiment-analysis-using-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from fastai.tabular import *\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn import svm, tree\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "\n",
    "from sklearn import model_selection\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/Users/bbabu/fastai/DataSamples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fnames = sorted(glob.glob('/Users/bbabu/fastai/DataSamples/NSE-*.csv'))\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for fname in fnames:\n",
    "    data = pd.read_csv(fname, header=0)\n",
    "    print(len(data))\n",
    "    df = df.append(data)\n",
    "\n",
    "df.to_csv(path/'NSE.csv', header=True, index=False)\n",
    "\n",
    "#df[240:249]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'NSE.csv', header=0)\n",
    "# df = pd.read_csv(path/'NSE2.csv', header=0)\n",
    "# df = pd.read_csv(path/'Test.csv', header=0)\n",
    "\n",
    "\n",
    "# df.dtypes\n",
    "# df.head()\n",
    "# len(df)\n",
    "# df[240:249]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting index as date\n",
    "df['Date'] = pd.to_datetime(df.Date,format='%Y-%m-%d')\n",
    "# df['Date'] = pd.to_datetime(df.Date,format='%d-%b-%Y')\n",
    "df.index = df['Date']\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(df['Close'], label='Close Price history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sorting\n",
    "# data = df.sort_index(ascending=True, axis=0)\n",
    "\n",
    "# data.head()\n",
    "\n",
    "# #creating a separate dataset\n",
    "# new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])\n",
    "\n",
    "# for i in range(0,len(data)):\n",
    "#     new_data['Date'][i] = data['Date'][i]\n",
    "#     new_data['Close'][i] = data['Close'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create features\n",
    "# add_datepart(new_data, 'Date')\n",
    "# new_data.drop('Elapsed', axis=1, inplace=True)  #elapsed will be the time stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data['mon_fri'] = 0\n",
    "# for i in range(0,len(new_data)):\n",
    "#     if (new_data['Dayofweek'][i] == 0 or new_data['Dayofweek'][i] == 4):\n",
    "#         new_data['mon_fri'][i] = 1\n",
    "#     else:\n",
    "#         new_data['mon_fri'][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #split into train and validation\n",
    "# train = new_data[:2000]\n",
    "# valid = new_data[2000:]\n",
    "\n",
    "# x_train = train.drop('Close', axis=1)\n",
    "# y_train = train['Close']\n",
    "# x_valid = valid.drop('Close', axis=1)\n",
    "# y_valid = valid['Close']\n",
    "\n",
    "# #implement linear regression\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# model = LinearRegression()\n",
    "# model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #make predictions and find the rmse\n",
    "# preds = model.predict(x_valid)\n",
    "# rms=np.sqrt(np.mean(np.power((np.array(y_valid)-np.array(preds)),2)))\n",
    "# rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot\n",
    "# valid['Predictions'] = 0\n",
    "# valid['Predictions'] = preds\n",
    "\n",
    "# valid.index = new_data[2000:].index\n",
    "# train.index = new_data[:2000].index\n",
    "\n",
    "# plt.plot(train['Close'])\n",
    "# plt.plot(valid[['Close', 'Predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    "data = df.sort_index(ascending=True, axis=0)\n",
    "new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])\n",
    "# new_data = pd.DataFrame(index=range(0,test,columns=['Date', 'Close'])\n",
    "\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "# for i in range(0,test):\n",
    "    new_data['Date'][i] = data['Date'][i]\n",
    "    new_data['Close'][i] = data['Close'][i]\n",
    "\n",
    "#setting index\n",
    "new_data.index = new_data.Date\n",
    "new_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "#creating train and test sets\n",
    "dataset = new_data.values\n",
    "\n",
    "train = dataset[0:2000,:]\n",
    "valid = dataset[2000:,:]\n",
    "\n",
    "#converting dataset into x_train and y_train\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for i in range(120,len(train)):\n",
    "    x_train.append(scaled_data[i-120:i,0])\n",
    "    y_train.append(scaled_data[i,0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(1)) \n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=4, verbose=2)\n",
    "\n",
    "#predicting 246 values, using past 120 from the train data\n",
    "inputs = new_data[len(new_data) - len(valid) - 120:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs  = scaler.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "for i in range(120,inputs.shape[0]):\n",
    "    X_test.append(inputs[i-120:i,0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "closing_price = model.predict(X_test)\n",
    "closing_price = scaler.inverse_transform(closing_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms=np.sqrt(np.mean(np.power((valid-closing_price),2)))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for plotting\n",
    "train = new_data[:2000]\n",
    "valid = new_data[2000:]\n",
    "valid['Predictions'] = closing_price\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close','Predictions']])\n",
    "\n",
    "print(valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??dropout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
